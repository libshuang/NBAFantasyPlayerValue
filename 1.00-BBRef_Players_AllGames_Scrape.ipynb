{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bcff95",
   "metadata": {},
   "source": [
    "#### Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f5b60",
   "metadata": {},
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471f357",
   "metadata": {},
   "source": [
    "## 1. League URL Link Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target web page:\n",
    "url = \"https://www.basketball-reference.com/leagues/NBA_\" + str(year) + \"_per_game.html\"\n",
    "\n",
    "# Establishing the connection to the web page:\n",
    "response = requests.get(url)\n",
    "\n",
    "print('Status Code: ',response.status_code)\n",
    "\n",
    "# Pull the HTML string out of requests and convert it to a Python string.\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dde3d9",
   "metadata": {},
   "source": [
    "## 1a. Scraping the NBA Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec450c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master block\n",
    "\n",
    "rows = soup.findAll('td')\n",
    "links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
    "\n",
    "#go through third link:  '/leagues/NBA_2022(year)_adj_shooting.html',\n",
    "counter = 0\n",
    "for i in range(0,len(links_with_text)):\n",
    "    if links_with_text[i] == '/leagues/NBA_' + str(year) + '_adj_shooting.html':\n",
    "        counter += 1\n",
    "    if counter == 3:\n",
    "        links_with_text = links_with_text[i+1:]\n",
    "        break\n",
    "        \n",
    "#remove at last link: '/leagues/NBA_2022.html',\n",
    "counter = 0\n",
    "for i in range(0,len(links_with_text)):\n",
    "    if links_with_text[i] == '/leagues/NBA_' + str(year) + '.html':\n",
    "        links_with_text = links_with_text[:i]\n",
    "        counter += 1\n",
    "    if counter == 1:\n",
    "        break\n",
    "        \n",
    "links_with_text = list(OrderedDict.fromkeys(links_with_text))\n",
    "links_with_text = [x for x in links_with_text if not x.startswith('/teams/')]\n",
    "links_with_text = [x.replace('.html', '/gamelog/') for x in links_with_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_with_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b803b",
   "metadata": {},
   "source": [
    "## 1b. Scraping the NBA Player Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_row = ['Player', 'Pos', 'Age', 'Tm', 'G', 'GS','MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "\n",
    "player_names = soup.findAll('tr')[1:]\n",
    "player_names_data = [[td.getText() for td in player_names[i].findAll('td')]\n",
    "                    for i in range(len(player_names))]\n",
    "\n",
    "df = pd.DataFrame(player_names_data,columns = header_row)\n",
    "df.dropna(how = 'all', inplace = True)\n",
    "\n",
    "df['Player'] = df['Player'].str.replace('*', '') #Remove all * from HoF\n",
    "\n",
    "player_list = df['Player'].tolist()\n",
    "player_list = list(OrderedDict.fromkeys(player_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32638d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b15ee",
   "metadata": {},
   "source": [
    "## 1c. Verification Size Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c747ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Links List == Play Name List\n",
    "len(links_with_text) == len(player_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343dc33",
   "metadata": {},
   "source": [
    "### 1d. Scrape Individual Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_header = ['Player', 'Year', 'G', 'Date', 'Age', 'Tm', '', 'Opp', '', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'GmSc', '+/-', 'Link']\n",
    "header = ['G', 'Date', 'Age', 'Tm', '', 'Opp', '', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'GmSc', '+/-']\n",
    "\n",
    "master_df = pd.DataFrame(columns = master_header)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bea82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(links_with_text)):\n",
    "\n",
    "    # Target web page:\n",
    "    url = \"https://www.basketball-reference.com\" + links_with_text[i] + str(year)\n",
    "\n",
    "    # Establishing the connection to the web page:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # You can use status codes to understand how the target server responds to your request.\n",
    "    # Ex., 200 = OK, 400 = Bad Request, 403 = Forbidden, 404 = Not Found.\n",
    "    print('Status Code for Link', links_with_text[i], ': ', response.status_code)\n",
    "\n",
    "    # Pull the HTML string out of requests and convert it to a Python string.\n",
    "    html = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "\n",
    "    rows = soup.findAll('tr')\n",
    "    rows_data = [[td.getText() for td in rows[x].findAll('td')]\n",
    "                        for x in range(len(rows))]\n",
    "\n",
    "    for j in range(0,len(rows_data)):\n",
    "        if rows_data[j] == []:\n",
    "            updated_rows_data = rows_data[j+1:]\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(updated_rows_data, columns = header)\n",
    "    df.dropna(how = 'all', inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.insert(loc=0, column='Player', value=player_list[i])\n",
    "    df.insert(loc=1, column='Year', value=year)\n",
    "    df['Link'] = links_with_text[i] + str(year)\n",
    "\n",
    "    master_df = pd.concat([master_df,df])\n",
    "    time.sleep(random.randrange(1, 7, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbbb97",
   "metadata": {},
   "source": [
    "## LOOP SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 3\n",
    "master_header = ['Player', 'Year', 'G', 'Date', 'Age', 'Tm', '', 'Opp', '', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'GmSc', '+/-', 'Link']\n",
    "header = ['G', 'Date', 'Age', 'Tm', '', 'Opp', '', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'GmSc', '+/-']\n",
    "master_df = pd.DataFrame(columns = master_header)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(links_with_text)):\n",
    "\n",
    "    #part 1\n",
    "    url = \"https://www.basketball-reference.com/leagues/NBA_\" + str(year) + \"_per_game.html\"\n",
    "    response = requests.get(url)\n",
    "    print('Status Code: ',response.status_code)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "\n",
    "    rows = soup.findAll('td')\n",
    "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
    "\n",
    "    #go through third link:  '/leagues/NBA_2022(year)_adj_shooting.html',\n",
    "    counter = 0\n",
    "    for i in range(0,len(links_with_text)):\n",
    "        if links_with_text[i] == '/leagues/NBA_' + str(year) + '_adj_shooting.html':\n",
    "            counter += 1\n",
    "        if counter == 3:\n",
    "            links_with_text = links_with_text[i+1:]\n",
    "            break\n",
    "\n",
    "    #remove at last link: '/leagues/NBA_2022.html',\n",
    "    counter = 0\n",
    "    for i in range(0,len(links_with_text)):\n",
    "        if links_with_text[i] == '/leagues/NBA_' + str(year) + '.html':\n",
    "            links_with_text = links_with_text[:i]\n",
    "            counter += 1\n",
    "        if counter == 1:\n",
    "            break\n",
    "\n",
    "    links_with_text = list(OrderedDict.fromkeys(links_with_text))\n",
    "    links_with_text = [x for x in links_with_text if not x.startswith('/teams/')]\n",
    "    links_with_text = [x.replace('.html', '/gamelog/') for x in links_with_text]\n",
    "    \n",
    "    #part 2\n",
    "    header_row = ['Player', 'Pos', 'Age', 'Tm', 'G', 'GS','MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "    player_names = soup.findAll('tr')[1:]\n",
    "    player_names_data = [[td.getText() for td in player_names[i].findAll('td')]\n",
    "                        for i in range(len(player_names))]\n",
    "    df = pd.DataFrame(player_names_data,columns = header_row)\n",
    "    df.dropna(how = 'all', inplace = True)\n",
    "    df['Player'] = df['Player'].str.replace('*', '') #Remove all * from HoF\n",
    "    player_list = df['Player'].tolist()\n",
    "    player_list = list(OrderedDict.fromkeys(player_list))\n",
    "    \n",
    "    time.sleep(4) #to make sure we dont get soft blocked\n",
    "    \n",
    "\n",
    "    # Target web page:\n",
    "    url = \"https://www.basketball-reference.com\" + links_with_text[i] + str(year)\n",
    "\n",
    "    # Establishing the connection to the web page:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    print('Status Code for Player', ': ',response.status_code)\n",
    "\n",
    "    # Pull the HTML string out of requests and convert it to a Python string.\n",
    "    html = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "\n",
    "    rows = soup.findAll('tr')\n",
    "    rows_data = [[td.getText() for td in rows[x].findAll('td')]\n",
    "                        for x in range(len(rows))]\n",
    "\n",
    "    for j in range(0,len(rows_data)):\n",
    "        if rows_data[j] == []:\n",
    "            updated_rows_data = rows_data[j+1:]\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(updated_rows_data, columns = header)\n",
    "    df.dropna(how = 'all', inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.insert(loc=0, column='Player', value=player_list[i])\n",
    "    df.insert(loc=1, column='Year', value=year)\n",
    "    df['Link'] = links_with_text[i] + str(year)\n",
    "\n",
    "    master_df = pd.concat([master_df,df])\n",
    "    time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
